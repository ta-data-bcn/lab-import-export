{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Accessing our database\n",
    "Create a connection to access the sakila database with the ip, user and password provided in class. Take a look at the data. Do some joins in order to have more elaborated tables in a dataframe (you can try first the query in the DBMS and then use it in your notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Tables_in_sakila\n",
      "0                        actor\n",
      "1                   actor_info\n",
      "2                      address\n",
      "3                     category\n",
      "4                         city\n",
      "5                      country\n",
      "6                     customer\n",
      "7                customer_list\n",
      "8                         film\n",
      "9                   film_actor\n",
      "10               film_category\n",
      "11                   film_list\n",
      "12                   film_text\n",
      "13                   inventory\n",
      "14                    language\n",
      "15  nicer_but_slower_film_list\n",
      "16                     payment\n",
      "17                      rental\n",
      "18      sales_by_film_category\n",
      "19              sales_by_store\n",
      "20                       staff\n",
      "21                  staff_list\n",
      "22                       store\n",
      "\n",
      "     customer_id first_name  last_name                   address address2  \\\n",
      "0              1       MARY      SMITH            1913 Hanoi Way            \n",
      "1              2   PATRICIA    JOHNSON          1121 Loja Avenue            \n",
      "2              3      LINDA   WILLIAMS         692 Joliet Street            \n",
      "3              4    BARBARA      JONES          1566 Inegl Manor            \n",
      "4              5  ELIZABETH      BROWN           53 Idfu Parkway            \n",
      "..           ...        ...        ...                       ...      ...   \n",
      "594          595   TERRENCE  GUNDERSON       844 Bucuresti Place            \n",
      "595          596    ENRIQUE   FORSYTHE  1101 Bucuresti Boulevard            \n",
      "596          597    FREDDIE     DUGGAN    1103 Quilmes Boulevard            \n",
      "597          598       WADE   DELVALLE       1331 Usak Boulevard            \n",
      "598          599     AUSTIN    CINTRON      1325 Fukuyama Street            \n",
      "\n",
      "         district postal_code            city  \n",
      "0        Nagasaki       35200          Sasebo  \n",
      "1      California       17886  San Bernardino  \n",
      "2          Attika       83579         Athenai  \n",
      "3        Mandalay       53561        Myingyan  \n",
      "4          Nantou       42399          Nantou  \n",
      "..            ...         ...             ...  \n",
      "594      Liaoning       36603         Jinzhou  \n",
      "595   West Greece       97661          Patras  \n",
      "596         Piura       52137         Sullana  \n",
      "597          Vaud       61960        Lausanne  \n",
      "598  Heilongjiang       27107           Tieli  \n",
      "\n",
      "[599 rows x 8 columns]\n",
      "\n",
      "     first_name last_name                  title\n",
      "0      PENELOPE   GUINESS       ACADEMY DINOSAUR\n",
      "1      PENELOPE   GUINESS   ANACONDA CONFESSIONS\n",
      "2      PENELOPE   GUINESS            ANGELS LIFE\n",
      "3      PENELOPE   GUINESS  BULWORTH COMMANDMENTS\n",
      "4      PENELOPE   GUINESS          CHEAPER CLYDE\n",
      "...         ...       ...                    ...\n",
      "5457      THORA    TEMPLE       TELEGRAPH VOYAGE\n",
      "5458      THORA    TEMPLE        TROJAN TOMORROW\n",
      "5459      THORA    TEMPLE        VIRGINIAN PLUTO\n",
      "5460      THORA    TEMPLE       WARDROBE PHANTOM\n",
      "5461      THORA    TEMPLE         WRONG BEHAVIOR\n",
      "\n",
      "[5462 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "driver   = 'mysql+pymysql:'\n",
    "user     = 'data-students' \n",
    "password = 'iR0nH@cK-D4T4B4S3'\n",
    "ip       = '34.65.10.136' \n",
    "database = 'sakila' \n",
    "\n",
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "print(pd.read_sql('SHOW TABLES;', engine))\n",
    "\n",
    "stalker_sql = '''\n",
    "SELECT c.customer_id, first_name, last_name, address, address2, district, postal_code, city\n",
    "FROM customer AS c\n",
    "JOIN address AS a ON c.address_id = a.address_id\n",
    "JOIN city AS ci ON a.city_id = ci.city_id;\n",
    "'''\n",
    "actors_career_sql = '''\n",
    "SELECT first_name, last_name, title \n",
    "FROM actor AS a\n",
    "JOIN film_actor AS fa ON a.actor_id = fa.actor_id\n",
    "JOIN film AS f ON fa.film_id = f.film_id\n",
    "GROUP BY fa.actor_id, fa.film_id;\n",
    "'''\n",
    "\n",
    "stalker_df = pd.read_sql(stalker_sql, engine)\n",
    "actors_career_df = pd.read_sql(actors_career_sql, engine)\n",
    "\n",
    "print('')\n",
    "print(stalker_df)\n",
    "print('')\n",
    "print(actors_career_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Working with JSON files\n",
    "\n",
    "Import the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, load the data in `nasa.json` in the `data` folder and load it into a pandas dataframe. Name the dataframe `nasa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "path = 'C:/Users/miner/Desktop/Ironhack/week2/lab-import-export/data/'\n",
    "file_name = 'nasa.json'\n",
    "nasa = pd.read_json(f'{path}{file_name}', orient = 'records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data, let's examine it using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "nasa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `value_counts()` function is commonly used in pandas to find the frequency of every value in a column.\n",
    "\n",
    "In the cell below, use the `value_counts()` function to determine the frequency of all types of asteroid landings by applying the function to the `fall` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "nasa.fall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's save the dataframe as a json file again. Save the dataframe using the `orient=records` argument and name the file `nasa-output.json`. Remember to save the file inside the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "file_json_out = 'nasa-output.json'\n",
    "nasa.to_json(f'{path}{file_json_out}', orient = 'records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Working with CSV and Other Separated Files\n",
    "\n",
    "CSV files are more commonly used as dataframes. In the cell below, load the file from the URL provided using the `read_csv()` function in pandas. Starting version 0.19 of pandas, you can load a CSV file into a dataframe directly from a URL without having to load the file first and then transform it. The dataset we will be using contains information about NASA shuttles.\n",
    "\n",
    "In the cell below, we define the column names and the URL of the data. Following this cell, read the tst file to a variable called `shuttle`. Since the file does not contain the column names, you must add them yourself using the column names declared in `cols` using the `names` argument. Additionally, a tst file is space separated, make sure you pass ` sep=' '` to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['time', 'rad_flow', 'fpv_close', 'fpv_open', 'high', 'bypass', 'bpv_close', 'bpv_open', 'class']\n",
    "tst_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/shuttle/shuttle.tst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "shuttle = pd.read_csv(tst_url, sep = ' ', names = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that this worked by looking at the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "shuttle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make life easier for us, let's turn this dataframe into a comma separated file by saving it using the `to_csv()` function. Save `shuttle` into the file `shuttle.csv` and ensure the file is comma separated, that we are not saving the index column and that the file is saved inside the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "file_csv_out = 'shuttle.csv'\n",
    "nasa.to_csv(f'{path}{file_csv_out}', sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Working with Excel Files\n",
    "\n",
    "We can also use pandas to convert excel spreadsheets to dataframes. Let's use the `read_excel()` function. In this case, `astronauts.xls` is in the `data` folder. Read this file into a variable called `astronaut`. \n",
    "\n",
    "Note: Make sure to install the `xlrd` library if it is not yet installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "file_name = 'astronauts.xls'\n",
    "astronaut = pd.read_excel(f'{path}{file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `head()` function to inspect the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "astronaut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `value_counts()` function to find the most popular undergraduate major among all astronauts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "astronaut['Undergraduate Major'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to all the commas present in the cells of this file, let's save it as a tab separated csv file. In the cell below, save `astronaut` as a **tab separated file** using the `to_csv` function. Call the file `astronaut.csv`. Remember to remove the index column and save the file in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "file_xls_out = 'astronaut.csv'\n",
    "astronaut.to_csv(f'{path}{file_xls_out}', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Fertility Dataset\n",
    "\n",
    "Visit the following [URL](https://archive.ics.uci.edu/ml/datasets/Fertility) and retrieve the dataset as well as the column headers. Determine the correct separator and read the file into a variable called `fertility`. Examine the dataframe using the `head()` function. \n",
    "\n",
    "Look in Google for a way to retrieve this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
